{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "692b9b8f-b0a4-43ce-a0a6-6645c3a7fe7b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# analyze_reaction_times\n",
    "\n",
    "Performs analysis of reaction time data for subjects categorizing images of animals. The data is simulated and the code is meant only to demonstrate basics of paths and file handling. See the `README.md` for further information.\n",
    "\n",
    "Part of the *Computational Fluency Short Course* offered in 2024 by Brown University's Carney Institute. Intended only for educational purposes; use at your own risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a3e4a1-c723-4518-a82e-0fc45858a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import block\n",
    "# Loads packages that extends base python\n",
    "\n",
    "import os  # Operating system utilities\n",
    "\n",
    "import pandas as pd  # Common package for working with tabular data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7651196b-3554-4319-a713-da617aa3776b",
   "metadata": {},
   "source": [
    "## Getting paths to the data\n",
    "\n",
    "As described in the course, different operating systems use slightly different conventions for describing paths. The most notable differences are that Linux and Mac use `/` as a separator while Windows uses `\\`, and the root directory on Linux and Max is `/`, while the Windows root is (usually) `C:\\`.\n",
    "\n",
    "In order to write code that works across operating systems, we have to check the OS and figure out the right convention to use. As a convenience, `python` provides the `os` module that does the work for us.\n",
    "\n",
    "A second issue is that we have to know where the data is, but if we use an absolute path that is correct on our computer, it will break when moved to a different computer. One way we can try to handle this situation is with *relative paths*, assuming we know the working directory set when the notebook starts up (sometimes this breaks also, especially on remote systems, and some troubleshooting is required). By default, opening a notebook within Jupyter Lab sets that notebook's local as the working dirtectory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15b32c9-9afe-4dc4-bf84-d40cc5452030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First pass at loading a data file:\n",
    "# Just assume it is in the current working directory\n",
    "\n",
    "#df = pd.read_csv('sub-1/sub-1_task-class_beh.csv')  # This will fail !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2298aa-1e39-40eb-a539-36dc43304efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second pass at loading a data file:\n",
    "# Use the absolute path on \"my\" computer\n",
    "\n",
    "#df = pd.read_csv('/Users/jritt/QENC/Teaching/2024_Spring/ComputationalFluency_2024/Content/Public/cfsc2024-ex-paths/testdata/sub-1/sub-1_task-class_beh.csv')\n",
    "# This will fail on everyone's computer except mine!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6af8d06-6280-48a1-8818-6688a55018b8",
   "metadata": {},
   "source": [
    "So how do we make a more sharable, portable data load? We need to build a path to a data directory. This repo includes small data files (remember to avoid large files in git repos!) in a directory called testdata.\n",
    "\n",
    "We also use the `os` module to deal with driectory names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ebb5c8-2010-4aa6-aa9e-83e6ef6721b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put together a path to the data\n",
    "\n",
    "# Look at the python kernel's working directory\n",
    "# Note this directory may not match wherever you started Jupyter Lab\n",
    "cwd = os.getcwd()  \n",
    "print(f'Current working directory:\\n{cwd}\\n')\n",
    "\n",
    "# Make a relative path to the data\n",
    "data_dir_rel = os.path.join('..','testdata')  # join adds the correct path separator\n",
    "# Doube dots \"..\" mean \"go up one directory\"\n",
    "print(f'Relative path to data:\\n{data_dir_rel}\\n')\n",
    "\n",
    "# Convert a relative path to absolute path\n",
    "data_dir = os.path.abspath(data_dir_rel)  \n",
    "print(f'Absolute path to data:\\n{data_dir}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df85a1d4-d3d6-420e-bfc9-331c7f3e50eb",
   "metadata": {},
   "source": [
    "Now we look in the data directory to find subject-wise subdirectories, and continue down to the data files.\n",
    "\n",
    "**Note**: It's usually a bad idea to blindly loop through everything within a directory. There will often be other kinds of files in there, either intentionally (like an index of subjects) or unintenitionally (automatically generated files and/or dot-files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05977dc-42fc-4ecb-8dd7-2133e45ef3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Content of {data_dir}:\\n')\n",
    "for name in os.listdir(data_dir):\n",
    "    is_subject = str.startswith(name,'sub-')  # Test the name\n",
    "    if is_subject:\n",
    "        print(f'Found subject data directory: {name}')\n",
    "    else:\n",
    "        print(f'Skipping other file {name}')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edd1283-72e6-4292-92b2-52794210b1a2",
   "metadata": {},
   "source": [
    "## Manually load some data\n",
    "\n",
    "As a demonstration, we load a single data file, and look at its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92e94cc-2474-408f-a11b-ca1ce29382fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(data_dir,'sub-1','sub-1_task-class_beh.csv')\n",
    "print(f'Loading data at {filepath}')\n",
    "\n",
    "df = pd.read_csv(filepath)  # Load data as a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70009434-4563-4132-bb2a-fc37773fb567",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd441a10-4992-4231-8893-3fc8c4bab3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4469ea10-0ea3-4c6a-8bec-9befce3a7f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract columns by name\n",
    "print('The set of reaction times is\\n', df[\"ReactionTime\"] )\n",
    "\n",
    "# Extract operations on columns via \"methods\"\n",
    "print(f'\\nThe mean reaction time is { df[\"ReactionTime\"].mean() } seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f23d126-317c-4c85-93f2-51badb8a6f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Exercise: find the standard deviation of RTs\n",
    "\n",
    "print(f'The standard deviation of reaction times is { df[\"ReactionTime\"].std() } seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3319abe6-9973-495b-9467-c895deda0604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Exercise: use the above results to make \"z-scored\" RTs, that is, \n",
    "#   subtract the mean and then divide by the standard deviation for all trials\n",
    "\n",
    "rt_mean = df[\"ReactionTime\"].mean()\n",
    "rt_std = df[\"ReactionTime\"].std()\n",
    "\n",
    "df[\"ReactionTimeZScore\"] = (df[\"ReactionTime\"] - rt_mean) / rt_std\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dea9eb-f0b3-4da7-ac42-a9efe87fe74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Exercise: find the three mean RTs separately for each type of trial (this\n",
    "# one is a little more advanced)\n",
    "\n",
    "trial_type_list = ['dog', 'bird', 'cat']\n",
    "\n",
    "for trial_type in trial_type_list:\n",
    "    df_cur = df[ df[\"TrialType\"] == trial_type ]\n",
    "    print(f'For { trial_type } trials, the mean reaction time is { df_cur[\"ReactionTime\"].mean() } seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9492309-9ca1-48a3-8c2c-ca85556841e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Exercise: find the two mean RTs separately for correct and incorrect\n",
    "# trials (this one is harder still, but follows from the previous exercise)\n",
    "\n",
    "is_correct = df[\"TrialType\"] == df[\"Response\"]\n",
    "df_correct = df[ is_correct ]\n",
    "df_incorrect = df[ ~is_correct ]  # ~ performs \"logical not\"\n",
    "\n",
    "print(f'The mean reaction time on correct trials is { df_correct[\"ReactionTime\"].mean() } seconds')\n",
    "print(f'The mean reaction time on incorrect trials is { df_incorrect[\"ReactionTime\"].mean() } seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f03d13a-0ab3-42c1-ac83-f4400e2d27ce",
   "metadata": {},
   "source": [
    "## Paths for loading code\n",
    "\n",
    "Sometimes we'd prefer to use our own custom code across multiple notebooks, for example to do some standardized data loading or pre-processing. We then put that code into a module (bassically just a `.py` file) or package, and then `import` it in the notebook.\n",
    "\n",
    "However, the python interpreter needs to know where to look for that code. It searches a \"path list\", that is automatically set when python is launched. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2442c52-a57a-4368-af21-c2c902fbd482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  # Access python system properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3354da51-a69b-4e68-8fbe-dc982b874da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = sys.path\n",
    "\n",
    "print('Python will search for code in the following directories (in order):\\n')\n",
    "for path in path_list:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3733a23f-026a-4404-b6bb-9873b49e3cb0",
   "metadata": {},
   "source": [
    "Note the empty line (it is not missing, it is actually an empty string). Python interprets the empty string as meaning whatever the current working directory is.\n",
    "\n",
    "We thus have several choices to load our code:\n",
    "- Put the module in the same directory as the notebook\n",
    "- Change the working directory to wherever the module is\n",
    "- Change the system path to include the location of the module\n",
    "- Package the module in a way that can be placed in a \"global\" location\n",
    "\n",
    "There are many opinions about best practice, and it often depends on the details of your project (for example, how globally useful the extra code is, and how many people are sharing it). For code that will be reused often, making a package may be the best option, though it takes a little extra work.\n",
    "\n",
    "We will demonstrate a kind of hack that can be useful in simple situations: we change directories to where the code should be, import it, then change back to where we started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5025bcd9-3b61-4c72-baca-1cd735435d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First try to import with just the module name (will fail !)\n",
    "\n",
    "#import datahandling as dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb279e0e-014b-4055-973d-2388d0aca698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hack to import code in another directory without changing the path list\n",
    "\n",
    "wd_orig = os.getcwd()\n",
    "\n",
    "wd_code = os.path.abspath( os.path.join('..','utils') )\n",
    "print(f'Attempt to load module in:\\n{wd_code}\\n')\n",
    "\n",
    "# We put in a try-except block so even if there's an error during import \n",
    "# we still get to code that will restore the working directory\n",
    "try:\n",
    "    os.chdir(wd_code)\n",
    "    import datahandling as dh\n",
    "    print('Import succeeded')\n",
    "except:  # If the try block crashes we end up here \n",
    "    print('Failed to load module; attempting to restore working directory ')\n",
    "\n",
    "os.chdir(wd_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bbe2f6-f078-446d-872b-fdc4705e1ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Current working directory is {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e3e47d-ca18-4c05-953c-6104f68b9794",
   "metadata": {},
   "source": [
    "Now let's use the utilities in `datahandling` to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48629fac-2466-42fb-b7ae-8027453df509",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = dh.load_subject(filepath)\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd23bb7-2fe9-4cfa-93d2-4c83bdebf143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that error handling in dh works as expected\n",
    "# This is a simple, informal example of using a \"unit test\"\n",
    "\n",
    "df3 = dh.load_subject('/nonsense/file/path') # Prints an error message\n",
    "assert df3 is None  # Nothing should happen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
